import sys
import subprocess 
from antlr4 import *

from generated.gramaticaLexer import gramaticaLexer
from generated.gramaticaParser import gramaticaParser

from semantic_analyzer.SemanticAnalyzerVisitor import SemanticAnalyzerVisitor
from codegen.PythonCodeGenerator import PythonCodeGenerator

def compile_source_code(source_code, job_index):
    """
    Funci√≥n que encapsula todo el pipeline de compilaci√≥n para un √∫nico trabajo (Job).
    Esto nos permite procesar varios flujos de trabajo de forma independiente.
    """
    
    print("\n" + "=" * 50)
    print(f"üöÄ INICIANDO COMPILACI√ìN (Trabajo #{job_index}) üöÄ")
    print("=" * 50)

    # 1. Verificaci√≥n preliminar (para saltar bloques vac√≠os despu√©s del split)
    if not source_code.strip():
        print("[INFO] Trabajo vac√≠o, omitiendo.")
        return

    # 2. Fases 1 y 2: An√°lisis L√©xico y Sint√°ctico
    try:
        input_stream = InputStream(source_code)
        lexer = gramaticaLexer(input_stream)
        stream = CommonTokenStream(lexer)
        parser = gramaticaParser(stream)
        
        print("Analizando sintaxis...")
        tree = parser.program() # Construye el Parse Tree (CST).
        print("[OK] An√°lisis L√©xico y Sint√°ctico Exitoso.")
    except Exception as e:
        # Si falla el try, capturamos el ERROR DE SINTAXIS y detenemos el trabajo.
        print(f"\n[ERROR] Error de Sintaxis Detectado (Trabajo #{job_index}):")
        print(e)
        return

    # 3. Fases 3 y 4: An√°lisis Sem√°ntico y Generaci√≥n de C√≥digo Intermedio (IR)
    print("\nIniciando An√°lisis Sem√°ntico y Generaci√≥n de IR...")
    try:
        semantic_visitor = SemanticAnalyzerVisitor()
        semantic_visitor.visit(tree) 
        
        print("[OK] An√°lisis Sem√°ntico Exitoso.")
        
        # Reportamos el resultado de la Fase 3 (Tabla de S√≠mbolos).
        print("-" * 40)
        print("Tabla de S√≠mbolos:")
        print(f"  Tareas: {list(semantic_visitor.symbol_table.tasks.keys())}")
        print(f"  Variables: {list(semantic_visitor.symbol_table.variables.keys())}")
        print("-" * 40)
        
        # Reportamos el resultado de la Fase 4 (C√≥digo Intermedio TAC).
        print("\nC√≥digo Intermedio (TAC):")
        print(semantic_visitor.ir)
        print("-" * 40)
        
    except Exception as e:
        # Si falla el try, capturamos el ERROR SEM√ÅNTICO (ej: tarea no definida) y detenemos el trabajo.
        print(f"\n[ERROR] Error Sem√°ntico Detectado (Trabajo #{job_index}):")
        print(e)
        return

    # 4. Fase 5: Generaci√≥n de C√≥digo Final (Python)
    print("\nIniciando Generaci√≥n de C√≥digo Final...")
    try:
        # Creamos el generador pasando nuestra lista de instrucciones TAC.
        py_generator = PythonCodeGenerator(semantic_visitor.ir.instructions)
        python_code = py_generator.generate()
        
        # Asignamos un nombre √∫nico al archivo de salida para cada trabajo.
        output_filename = f"output_program_{job_index}.py"
        
        # Escribimos el script Python generado al disco.
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(python_code)
        print(f"[OK] C√≥digo Python generado y guardado en: {output_filename}")
        
    except Exception as e:
        # Manejo de errores de escritura.
        print(f"\n[ERROR] No se pudo escribir el archivo de salida (Trabajo #{job_index}): {e}")
        return

    # 5. Fase 6: Ejecuci√≥n del script generado (Prueba de Fuego)
    print(f"\nEjecutando {output_filename}...")
    try:
        # Usamos subprocess.run para ejecutar el archivo .py con el int√©rprete de Python del sistema.
        # Esto verifica que el c√≥digo generado sea realmente ejecutable.
        result = subprocess.run(
            [sys.executable, output_filename],
            capture_output=True, text=True, check=True
        )
        print("--- SALIDA DEL SCRIPT ---")
        print(result.stdout.strip()) # Imprimimos lo que el script compilado hizo.
        print("-------------------------")
        
    except subprocess.CalledProcessError as e:
        # Si el script Python generado tiene un error en tiempo de ejecuci√≥n.
        print(f"\n[ERROR] El script (Trabajo #{job_index}) fall√≥ al ejecutarse.")
        print(e.stdout)
        print(e.stderr)
    except Exception as e:
        # Otros errores de ejecuci√≥n.
        print(f"\n[ERROR] No se pudo ejecutar el script (Trabajo #{job_index}): {e}")


def main():
    """
    Punto de entrada principal. Se encarga de la lectura del archivo de entrada
    y de la separaci√≥n de los trabajos.
    """
    input_filename = "input.txt"
    separator = "---NUEVO_TRABAJO---" # Nuestro delimitador customizado.
    
    # Lectura del archivo de entrada completo
    try:
        with open(input_filename, "r", encoding="utf-8") as f:
            file_content = f.read()
    except FileNotFoundError:
        print(f"Error: No se encontr√≥ el archivo '{input_filename}'")
        return
    except Exception as e:
        print(f"Error leyendo archivo: {e}")
        return

    # Dividir el contenido del archivo por el separador customizado.
    jobs = file_content.split(separator)
    
    print(f"‚úÖ Se encontraron {len(jobs)} trabajos en '{input_filename}'.")
    
    # Iterar y llamar a la funci√≥n de compilaci√≥n para cada bloque.
    for i, job_code in enumerate(jobs):
        compile_source_code(job_code, i + 1)
        
    print("\n" + "=" * 50)
    print("¬°COMPILACI√ìN DE TODOS LOS TRABAJOS FINALIZADA!")
    print("=" * 50)

if __name__ == '__main__':
    main()